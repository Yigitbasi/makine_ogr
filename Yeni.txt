Makine öğrenmesi yapay zekanın bir dalıdır. 
Genellikle istatistiksel olarak çalışır ve verilere büyük oranda bağlıdır. Bu daha çok veriye ve doğru algoritmaya bağlıdır.
Kural tabanlı olarak çalışır. Tahminlerini buna uygun şekilde yapar.
Veri olmadan makine öğrenmesi algoritmaları kullanılamaz.
Başarılı bir sonuç almak için verilerin doğru olması gerekir. Aksi takdirde eksik ya da hatalı veriler sonucu manipüle edebilir.
Veriler işlendikten ve düzenlendikten sonra grafiğe çevrilir.
Üzerinde çalışılacak veriler ayrıştırılır. (target)
veriler test ve eğitim verilerine ayrılır. (doğrulamaya da ayrılabiliyor. validation)
Model eğitilir
Test için tahmin fonksiyonu oluşturulur.
Doğruluk kontrol edilir. (Hata matrisi)

Bazı makine öğrenmesi algoritmaları:
Karar ağaçları
Sinir ağları
Olasılık ağları
KNN
SVM

Makine öğrenmesi algoritmaları:
Regresyon
Sürekli değerleri tahmin etmek için kullanılır. 
(lineer regresyon, lojistik regresyon, üstel regresyon, polinom regresyon, logaritmik regresyon)
Sınıflandırma
Bir dizi öğenin(mesela sağlık verileri) sınıfını veya kategorisini tahmin etmek(hastalık durumu) için sınıflandırma algoritmaları kullanılır. 
(KNN, Karar ağaçları, Rastgele orman, SVM,Naive bayes)
Kümeleme
Verileri yapılandırmak için kümeleme algoritmaları kullanılır.
(K-means, DBSCAN, Mean shift, Hierarchical)
İlişkilendirme
Birlikte meydana gelen öğeleri veya olayları ilişkilendirmek için ilişkilendirme algoritmaları kullanıyoruz.
Apriori



KNN: 
K-En Yakın Komşular (KNN), hem sınıflandırma hem de regresyon görevleri için kullanılabilen basit bir denetimli makine öğrenimi algoritmasıdır.Temel fikir, bir veri noktasının tahmin edilmesinde, o noktaya en yakın komşularının etkisini kullanmaktır.
Çalışma adımları: 
Veri setini yükleyin
Veriyi eğitim ve test setlerine ayırın
Veriyi ölçeklendirin(Normalizasyon)
KNN modelini oluşturun ve eğitin
Tahmin yapın
Doğruluk(accuracy) hesapla

import numpy as np
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import accuracy_score

# Veri setini yükleyin
iris = load_iris()
X, y = iris.data, iris.target

# Veriyi eğitim ve test setlerine ayırın
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Veriyi ölçeklendirin
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# KNN modelini oluşturun
knn = KNeighborsClassifier(n_neighbors=3)

# Modeli eğitim verisi ile eğitin
knn.fit(X_train, y_train)

# Test seti ile tahmin yapın
y_pred = knn.predict(X_test)

# Doğruluk skorunu hesaplayın
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")


Lojistik Regresyon:
Lojistik Regresyon, bağımsız değişkenlerin ağırlıklarını ve etkilerini kullanarak, her bir sınıfın olasılığını tahmin eder. Ancak, doğrudan sınıfların tahmin edilmesi yerine, bir girişin her sınıfa ait olma olasılığı verilir. Bu olasılıklar daha sonra bir eşik değeri (threshold) kullanılarak sınıflara dönüştürülür.

from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score

# Veri setini yükleyin
iris = load_iris()
X, y = iris.data, iris.target

# Veriyi eğitim ve test setlerine ayırın
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Lojistik regresyon modelini oluşturun
logreg = LogisticRegression(max_iter=200)

# Modeli eğitim verisi ile eğitin
logreg.fit(X_train, y_train)

# Test seti ile tahmin yapın
y_pred = logreg.predict(X_test)

# Doğruluk skorunu hesaplayın
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

SVM:
Destek vektör makineleri:
Bir destek vektör makinesi (SVM), hem sınıflandırma hem de regresyon görevleri için kullanılabilen denetimli bir makine öğrenimi algoritmasıdır. İki sınıfın örnekleri arasındaki en büyük farkla farklı sınıfları ayırmak için bir hiper düzlem kullanır. Bu, modelin genelleme yeteneğini geliştirmeye yardımcı olur.
SVM, bu marjini maksimize eden hiperdüzlemi seçer, böylece yeni veri noktaları sınıflandırılırken daha iyi genelleme yapabilir.

import pandas as pd

veri = pd.read_csv("/kaggle/input/default-of-credit-card-clients-dataset/UCI_Credit_Card.csv")

print(veri.head())

from sklearn.model_selection import train_test_split

X = veri.drop("default.payment.next.month", axis=1)
y = veri["default.payment.next.month"]

X_egitim, X_test, y_egitim, y_test = train_test_split(X, y, test_size=0.25, random_state=0)

from sklearn.preprocessing import StandardScaler

scaler = StandardScaler()
X_egitim = scaler.fit_transform(X_egitim)
X_test = scaler.transform(X_test)

from sklearn.svm import SVC

svm_modeli = SVC(kernel='linear')
svm_modeli.fit(X_egitim, y_egitim)

dogruluk = svm_modeli.score(X_test, y_test)
print("Model Doğruluğu:", dogruluk)

Random Forest:
Rastgele orman, eğitim sırasında çok sayıda karar ağacı oluşturarak ve tek tek ağaçların sınıflarının modu olan sınıfı çıkararak çalışan, topluluk denetimli bir makine öğrenimi algoritmasıdır. Verilerin büyük bir kısmı eksik olduğunda doğruluğu korur.
Random Forest algoritması, birden fazla karar ağacının (decision tree) oluşturulmasını içerir. Her karar ağacı, rastgele örneklerle (bootstrap sampling) ve rastgele özelliklerle (feature sampling) eğitilir. Bu şekilde, her bir karar ağacı farklı bir alt küme veri ve özellik kümesi üzerinde eğitilir, bu da modele çeşitlilik katar.
Random Forest'ın avantajları arasında yüksek doğruluk, overfitting'e karşı direnç, farklı özellik türlerini (kategorik, sayısal) bir arada kullanabilme yeteneği ve dengesiz veri setlerinde etkili performans gösterme kabiliyeti bulunur.


# Import libraries
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, confusion_matrix

# Load data

df = pd.read_csv("/kaggle/input/pima-indians-diabetes-database/diabetes.csv")

# Exploratory data analysis 
print(df.shape)
print(df.describe())

# Preprocess data
X = df.drop('Outcome', axis=1) 
y = df['Outcome']

# Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train model
rf = RandomForestClassifier(n_estimators=100)
rf.fit(X_train, y_train)

# Evaluate model 
y_pred = rf.predict(X_test)
print('Accuracy:', accuracy_score(y_test, y_pred))

Decision Trees:
Karar ağaçları, birçok makine öğrenimi algoritmasından biridir ve sınıflandırma ve regresyon problemlerinde kullanılır. Bir karar ağacı, bir veri kümesindeki özelliklere dayalı olarak bir dizi karar düğümü ve sonuçları olan yaprak düğümleri içeren bir ağaç yapısıdır. Karar ağaçları, veri kümesini belirli özelliklere göre bölerek ve her düğümdeki en uygun bölünmeyi seçerek veri kümesini sınıflandırmak veya regresyon yapmak için kullanılır. 
Daha hızlı eğitim süreci


import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score

df = pd.read_csv('/kaggle/input/uci-ml-datasets/hou_all.csv')

X = df.drop('0', axis=1)
y = df['0']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

#Degerlendir ve Tahmin Et
clf = DecisionTreeClassifier()
clf.fit(X_train, y_train)
y_pred = clf.predict(X_test)

#Dogruluk degeri dondur
accuracy = accuracy_score(y_test, y_pred)
print(f'Accuracy: {accuracy}')
print(confusion_matrix(y_test, y_pred))

Naive Bayes:
Bayes Teoremi, bir olayın gerçekleşme olasılığını, bu olayın meydana gelmesine ilişkin kanıtlara dayanarak güncellemeyi sağlayan bir formül olarak tanımlanır


from sklearn.model_selection import train_test_split
from sklearn.naive_bayes import GaussianNB
from sklearn import metrics
import pandas as pd

df = pd.read_csv('/kaggle/input/malware-executable-detection/uci_malware_detection.csv')

X = df.drop('Label', axis=1)
y = df['Label']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)

#Naive Bayes Sınıflandırıcısını Başlat
gnb = GaussianNB()

gnb.fit(X_train, y_train)

y_pred = gnb.predict(X_test)
print("Accuracy:",metrics.accuracy_score(y_test, y_pred))
print(confusion_matrix(y_test, y_pred))

K-Means:
K-Means kümeleme, veri noktalarını belirli sayıda küme veya k-merkezine göre gruplandırır. Algoritma, önceden belirlenmiş k sayısında küme merkezlerini rastgele yerleştirir ve veri noktalarını bu merkezlere göre gruplandırır. Ardından, küme merkezleri tekrar hesaplanır ve veri noktaları bu yeni merkezlere göre yeniden gruplandırılır. Bu işlem, küme merkezlerinin hareket etmeyene kadar veya belirli bir iterasyon sayısına ulaşılana kadar tekrarlanır.

import pandas as pd
from sklearn.cluster import KMeans, AgglomerativeClustering
from sklearn.mixture import GaussianMixture
from sklearn.model_selection import train_test_split
from sklearn.metrics import silhouette_score

# Veri setini yükleme ve ön işleme
df = pd.read_csv('/kaggle/input/dry-bean-dataset/Dry_Bean.csv')

# Bağımlı değişken (y) ve bağımsız değişkenler (X) olarak ayırma
X = df.iloc[:, :-1].values
y = df.iloc[:, -1].values

# Veri setini train ve test olarak ayırma
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# K-Means Kümeleme
kmeans = KMeans(n_clusters=5) #5 parçaya ayrılır
kmeans.fit(X_train) 
kmeans_labels = kmeans.predict(X_test)
kmeans_silhouette_score = silhouette_score(X_test, kmeans_labels)

# Sonuçları değerlendirme
print("K-Means Silhouette Score:", kmeans_silhouette_score)
